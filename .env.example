# =============================================================================
# vLLM Docker Configuration Template
# =============================================================================
# Copy this file to .env and customize for your setup
# cp .env.example .env

# Data paths - change to your preferred location
# Use forward slashes for Docker compatibility
VLLM_DATA_ROOT=C:/DockerData/vllm
OPENWEBUI_DATA_ROOT=C:/DockerData/open-webui

# HuggingFace token (optional, only needed for gated models)
HF_TOKEN=

# vLLM version (v0.12.0, v0.13.0, nightly, latest)
VLLM_VERSION=v0.13.0

# GPU configuration
# RTX 5090 32GB: GPU_MEM_UTIL=0.90
# RTX 4090 24GB: GPU_MEM_UTIL=0.85
# Shared mode (running other GPU tasks): GPU_MEM_UTIL=0.65
GPU_MEM_UTIL=0.90
MAX_MODEL_LEN=32768
MAX_NUM_SEQS=16

# Model selection
VLLM_MODEL=Qwen/Qwen3-VL-4B-Instruct
